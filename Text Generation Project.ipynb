{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\koushik\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (1.29.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (45.2.0.post20200210)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.5.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\koushik\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from nltk) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\koushik\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from keras) (1.18.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from keras) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from keras) (1.1.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\koushik\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Koushik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import dependencies\n",
    "import numpy\n",
    "import sys\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "file = open(\"frankenstein-2.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'London was our present point of rest; we determined to remain several months in this wonderful and celebrated city. Clerval desired the intercourse of the men of genius and talent who flourished at this time, but this was with me a secondary object; I was principally occupied with the means of obtaining the information necessary for the completion of my promise and quickly availed myself of the letters of introduction that I had brought with me, addressed to the most distinguished natural philosophers.\\n\\nIf this journey had taken place during my days of study and happiness, it would have afforded me inexpressible pleasure. But a blight had come over my existence, and I only visited these people for the sake of the information they might give me on the subject in which my interest was so terribly profound. Company was irksome to me; when alone, I could fill my mind with the sights of heaven and earth; the voice of Henry soothed me, and I could thus cheat myself into a transitory peace. But busy, uninteresting, joyous faces brought back despair to my heart. I saw an insurmountable barrier placed between me and my fellow men; this barrier was sealed with the blood of William and Justine, and to reflect on the events connected with those names filled my soul with anguish.\\n\\nBut in Clerval I saw the image of my former self; he was inquisitive and anxious to gain experience and instruction. The difference of manners which he observed was to him an inexhaustible source of instruction and amusement. He was also pursuing an object he had long had in view. His design was to visit India, in the belief that he had in his knowledge of its various languages, and in the views he had taken of its society, the means of materially assisting the progress of European colonization and trade. In Britain only could he further the execution of his plan. He was for ever busy, and the only check to his enjoyments was my sorrowful and dejected mind. I tried to conceal this as much as possible, that I might not debar him from the pleasures natural to one who was entering on a new scene of life, undisturbed by any care or bitter recollection. I often refused to accompany him, alleging another engagement, that I might remain alone. I now also began to collect the materials necessary for my new creation, and this was to me like the torture of single drops of water continually falling on the head. Every thought that was devoted to it was an extreme anguish, and every word that I spoke in allusion to it caused my lips to quiver, and my heart to palpitate.\\n\\nAfter passing some months in London, we received a letter from a person in Scotland who had formerly been our visitor at Geneva. He mentioned the beauties of his native country and asked us if those were not sufficient allurements to induce us to prolong our journey as far north as Perth, where he resided. Clerval eagerly desired to accept this invitation, and I, although I abhorred society, wished to view again mountains and streams and all the wondrous works with which Nature adorns her chosen dwelling-places.\\n\\nWe had arrived in England at the beginning of October, and it was now February. We accordingly determined to commence our journey towards the north at the expiration of another month. In this expedition we did not intend to follow the great road to Edinburgh, but to visit Windsor, Oxford, Matlock, and the Cumberland lakes, resolving to arrive at the completion of this tour about the end of July. I packed up my chemical instruments and the materials I had collected, resolving to finish my labours in some obscure nook in the northern highlands of Scotland.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "#standardization\n",
    "def tokenize_words(input):\n",
    "    input=input.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "    filtered = filter(lambda token:token not in stopwords.words('english'),tokens)\n",
    "    return \"\".join(filtered)\n",
    "\n",
    "processed_inputs = tokenize_words(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chars to numbers\n",
    "chars = sorted(list(set(processed_inputs)))\n",
    "char_to_num = dict((c,i) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 2030\n",
      "Total vocab 26\n"
     ]
    }
   ],
   "source": [
    "#check if words to chars or chars to num \n",
    "input_len=len(processed_inputs)\n",
    "vocab_len=len(chars)\n",
    "print(\"Total number of characters:\",input_len)\n",
    "print(\"Total vocab\",vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq length\n",
    "seq_length=100\n",
    "x_data=[]\n",
    "y_data=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 1930\n"
     ]
    }
   ],
   "source": [
    "#loop through the sequence\n",
    "for i in range(0,input_len - seq_length,1):\n",
    "    in_seq = processed_inputs[i:i + seq_length]\n",
    "    out_seq = processed_inputs[i+seq_length]\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append(char_to_num[out_seq])\n",
    "    \n",
    "n_patterns = len(x_data)\n",
    "print(\"Total Patterns:\",n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert input sequence to np array and so on\n",
    "X =numpy.reshape(x_data,(n_patterns,seq_length,1))\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256,input_shape=(X.shape[1],X.shape[2]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the weights\n",
    "filepath = \"model_weights_saved.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath,monitor='loss',verbose=1,save_best_only=True,mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1930/1930 [==============================] - 37s 19ms/step - loss: 3.1053\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.10530, saving model to model_weights_saved.hdf5\n",
      "Epoch 2/4\n",
      "1930/1930 [==============================] - 39s 20ms/step - loss: 2.9830\n",
      "\n",
      "Epoch 00002: loss improved from 3.10530 to 2.98297, saving model to model_weights_saved.hdf5\n",
      "Epoch 3/4\n",
      "1930/1930 [==============================] - 42s 22ms/step - loss: 2.9719\n",
      "\n",
      "Epoch 00003: loss improved from 2.98297 to 2.97194, saving model to model_weights_saved.hdf5\n",
      "Epoch 4/4\n",
      "1930/1930 [==============================] - 39s 20ms/step - loss: 2.9649\n",
      "\n",
      "Epoch 00004: loss improved from 2.97194 to 2.96493, saving model to model_weights_saved.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b6b498b448>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model and train the data\n",
    "model.fit(X,y,epochs=4,batch_size=256,callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recompile the model with same weights\n",
    "filename=\"model_weights_saved.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output of the model back to characters\n",
    "num_to_char = dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: \n",
      "\" peditionintendfollowgreatroadedinburghvisitwindsoroxfordmatlockcumberlandlakesresolvingarrivecomplet \"\n"
     ]
    }
   ],
   "source": [
    "#random seed to help generate\n",
    "start = numpy.random.randint(0,len(x_data)-1)\n",
    "pattern = x_data[start]\n",
    "print(\"Random Seed: \")\n",
    "print(\"\\\"\",''.join([num_to_char[value] for value in pattern]),\"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
     ]
    }
   ],
   "source": [
    "#generate the text\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern,(1,len(pattern),1))\n",
    "    x = x/float(vocab_len)\n",
    "    prediction =  model.predict(x,verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = num_to_char[index]\n",
    "    seq_in = [num_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
